import os
import requests
from dotenv import load_dotenv
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langchain.agents import create_agent
from langgraph.checkpoint.memory import MemorySaver
from agent_tool import get_weather,get_air_quality


# ç¡®ä¿åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆé€šå¸¸åœ¨æ–‡ä»¶é¡¶éƒ¨å·²æœ‰ï¼‰
load_dotenv()
# åˆå§‹åŒ–è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰
llm = ChatOpenAI(temperature=0)
# åˆ›å»ºæ£€æŸ¥ç‚¹ä¿å­˜å™¨ï¼ˆå®ç°è®°å¿†çš„å…³é”®ï¼‰
memory_saver = MemorySaver()
# å®šä¹‰æ™ºèƒ½ä½“çš„å·¥å…·
agent_tools = [get_weather,get_air_quality]

# åˆ›å»ºæ™ºèƒ½ä½“
agent = create_agent(
    model=llm,
    tools=agent_tools,#å·¥å…·åˆ—è¡¨
    system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¤©æ°”åŠ©æ‰‹ï¼Œè´Ÿè´£å›ç­”ç”¨æˆ·å…³äºå¤©æ°”å’Œç©ºæ°”è´¨é‡çš„é—®é¢˜ã€‚",
    checkpointer=memory_saver, #å¯ç”¨ï¼Œä¿æŒå¯¹è¯è®°å¿†
    debug=True, #å¼€å¯è°ƒè¯•æ¨¡å¼ï¼ŒæŸ¥çœ‹æ™ºèƒ½ä½“çš„æ€è€ƒè¿‡ç¨‹
)
# æµ‹è¯•æ™ºèƒ½ä½“f
def run_test():
    print("="*50)
    print("å¼€å§‹æµ‹è¯•æ™ºèƒ½åŸå¸‚ç”Ÿæ´»åŠ©æ‰‹")
    print("="*50)

    # ğŸ“ æµ‹è¯•1ï¼šåœ¨ user_001 çº¿ç¨‹ä¸­è¿›è¡Œå¤šè½®å¯¹è¯ï¼Œè§‚å¯Ÿä¸Šä¸‹æ–‡ä¿æŒ
    print("\nğŸ§ª [æµ‹è¯•1] çº¿ç¨‹ 'user_001' - å¤šè½®å¯¹è¯ï¼ˆä¸Šä¸‹æ–‡ä¿æŒï¼‰")
    config_001 = {"configurable": {"thread_id": "user_001"}}

    # ç¬¬ä¸€è½®ï¼šç”¨æˆ·æŸ¥è¯¢é‡åº†å¤©æ°”
    question ="é‡åº†ä»Šå¤©å‡ºé—¨éœ€è¦å¸¦ä¼å—ï¼Œç©ºæ°”å¥½ä¸å¥½"
    print(f"\n[ç”¨æˆ·]: {question}")
    result = agent.invoke({"messages": [{"role": "user", "content": question}]}, config_001)

    # éå†æ¶ˆæ¯ï¼Œæ‰¾åˆ°æœ€åä¸€æ¡æ¥è‡ªAIä¸”åŒ…å«å®é™…å†…å®¹çš„å›å¤
    for msg in reversed(result['messages']): # ä»åå¾€å‰éå†æ¶ˆæ¯
        if hasattr(msg,'type') and msg.type == 'ai' and msg.content:
            print(f"[aiæ™ºèƒ½åŸå¸‚ç”Ÿæ´»åŠ©æ‰‹]: {msg.content}")
            break

if __name__ == '__main__':
    run_test()




